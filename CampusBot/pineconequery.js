import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import dotenv from "dotenv";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { Pinecone } from "@pinecone-database/pinecone";
import { PineconeStore } from "@langchain/pinecone";
import readline from 'readline';

// âœ… Load environment variables
dotenv.config();

(async () => {
  try {
    console.log("ğŸš€ Connecting to Pinecone...");

    // âœ… Initialize Pinecone
    const pinecone = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY,
    });

    console.log("âœ… Connected to Pinecone");

    // âœ… Connect to the index
    const index = pinecone.Index(process.env.PINECONE_INDEX_NAME);

    // âœ… Use Google's Gemini API for embeddings
    const embeddings = new GoogleGenerativeAIEmbeddings({
      model: "text-embedding-004",
      taskType: "RETRIEVAL_DOCUMENT",
    });

    // âœ… Initialize PineconeStore from the existing index
    const vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
      pineconeIndex: index,
    });

    console.log("âœ… PineconeStore initialized");

    // âœ… Use ChatGoogleGenerativeAI from LangChain
    const model = new ChatGoogleGenerativeAI({
      apiKey: process.env.GOOGLE_API_KEY,
      model: "gemini-2.0-flash",
    });

    console.log("âœ… Gemini AI Model Loaded");

    // âœ… Function to query Pinecone and get AI-generated answers
    const queryAndGenerateResponse = async (query) => {
      console.log(`ğŸ” Searching for: "${query}"...`);

      // âœ… Perform similarity search in Pinecone
      const retrievedDocs = await vectorStore.similaritySearch(query, 5);

      if (retrievedDocs.length === 0) {
        return "âŒ No relevant information found in the knowledge base.";
      }

      // âœ… Combine document content with emphasis on location
      const docsContent = retrievedDocs.map(doc => doc.pageContent).join("\n");

      // âœ… Generate response using Gemini with specific location prompt
      const fullPrompt = `Answer the following question based on the provided context. Focus on location details if relevant.\n\nContext:\n${docsContent}\n\nQuestion: ${query}`;

      const result = await model.invoke(fullPrompt);
      return result.text;
    };

    // âœ… Interactive Loop for Questions
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout
    });

    function askQuestion(query) {
      return new Promise(resolve => rl.question(query, resolve));
    }

    let query = await askQuestion("ğŸ’¬ Ask your question (type 'exit' to quit): ");
    while (query.toLowerCase() !== "exit") {
      const answer = await queryAndGenerateResponse(query);
      console.log("ğŸ¤– Answer:", answer);

      query = await askQuestion("\nğŸ’¬ Ask another question (or type 'exit' to quit): ");
    }

    rl.close();
    console.log("ğŸ‘‹ Chatbot session ended.");

  } catch (error) {
    console.error("âŒ Error:", error.message);
  }
})();
